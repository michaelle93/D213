{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Can the model accurately predict future negative and positive reviews?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The objective is to build a neural network model to train and test a dataset to predict new data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TensorFlow and Kera libraries are capable of performing text classification, the type of neural network that performs this task is a recurrent neural network (RNN)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as mlp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "amazon = open('amazon_cells_labelled.txt').read()\n",
    "\n",
    "a_labels, a_texts = [],[]\n",
    "for i, line in enumerate(amazon.split('\\n')):\n",
    "    content = line.split('\\t')\n",
    "    if len(content) > 1:\n",
    "        a_texts.append(content[0])\n",
    "        a_labels.append(content[1])\n",
    "        \n",
    "df_a = pd.DataFrame()\n",
    "df_a['label'] = a_labels\n",
    "df_a['text'] = a_texts\n",
    "df_a['source'] = 'amazon'\n",
    "\n",
    "imdb = open('imdb_labelled.txt').read()\n",
    "\n",
    "i_labels, i_texts = [],[]\n",
    "for i, line in enumerate(imdb.split('\\n')):\n",
    "    content = line.split('\\t')\n",
    "    if len(content) > 1:\n",
    "        i_texts.append(content[0])\n",
    "        i_labels.append(content[1])\n",
    "        \n",
    "df_i = pd.DataFrame()\n",
    "df_i['label'] = i_labels\n",
    "df_i['text'] = i_texts\n",
    "df_i['source'] = 'imdb'\n",
    "\n",
    "yelp = open('yelp_labelled.txt').read()\n",
    "\n",
    "y_labels, y_texts = [],[]\n",
    "for i, line in enumerate(yelp.split('\\n')):\n",
    "    content = line.split('\\t')\n",
    "    if len(content) > 1:\n",
    "        y_texts.append(content[0])\n",
    "        y_labels.append(content[1])\n",
    "        \n",
    "df_y = pd.DataFrame()\n",
    "df_y['label'] = y_labels\n",
    "df_y['text'] = y_texts\n",
    "df_y['source'] = 'yelp'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text  source\n",
       "0     0  So there is no way for me to plug it in here i...  amazon\n",
       "1     1                        Good case, Excellent value.  amazon\n",
       "2     1                             Great for the jawbone.  amazon\n",
       "3     0  Tied to charger for conversations lasting more...  amazon\n",
       "4     1                                  The mic is great.  amazon"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>A very, very, very slow-moving, aimless movie ...</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Not sure who was more lost - the flat characte...</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Attempting artiness with black &amp; white and cle...</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Very little music or anything to speak of.</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The best scene in the movie was when Gerardo i...</td>\n",
       "      <td>imdb</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text source\n",
       "0     0  A very, very, very slow-moving, aimless movie ...   imdb\n",
       "1     0  Not sure who was more lost - the flat characte...   imdb\n",
       "2     0  Attempting artiness with black & white and cle...   imdb\n",
       "3     0       Very little music or anything to speak of.     imdb\n",
       "4     1  The best scene in the movie was when Gerardo i...   imdb"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Wow... Loved this place.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>Crust is not good.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>Not tasty and the texture was just nasty.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>Stopped by during the late May bank holiday of...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The selection on the menu was great and so wer...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  label                                               text source\n",
       "0     1                           Wow... Loved this place.   yelp\n",
       "1     0                                 Crust is not good.   yelp\n",
       "2     0          Not tasty and the texture was just nasty.   yelp\n",
       "3     1  Stopped by during the late May bank holiday of...   yelp\n",
       "4     1  The selection on the menu was great and so wer...   yelp"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "(1000, 3)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_a.head())\n",
    "display(df_a.shape)\n",
    "display(df_i.head())\n",
    "display(df_i.shape)\n",
    "display(df_y.head())\n",
    "display(df_y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3000 entries, 0 to 2999\n",
      "Data columns (total 3 columns):\n",
      " #   Column  Non-Null Count  Dtype \n",
      "---  ------  --------------  ----- \n",
      " 0   label   3000 non-null   int32 \n",
      " 1   text    3000 non-null   object\n",
      " 2   source  3000 non-null   object\n",
      "dtypes: int32(1), object(2)\n",
      "memory usage: 58.7+ KB\n"
     ]
    }
   ],
   "source": [
    "df = pd.concat([df_a, df_i, df_y], ignore_index=True)\n",
    "df.label = df.label.astype(int)\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>amazon</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>yelp</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  source\n",
       "0         0  So there is no way for me to plug it in here i...  amazon\n",
       "1         1                        Good case, Excellent value.  amazon\n",
       "2         1                             Great for the jawbone.  amazon\n",
       "3         0  Tied to charger for conversations lasting more...  amazon\n",
       "4         1                                  The mic is great.  amazon\n",
       "...     ...                                                ...     ...\n",
       "2995      0  I think food should have flavor and texture an...    yelp\n",
       "2996      0                           Appetite instantly gone.    yelp\n",
       "2997      0  Overall I was not impressed and would not go b...    yelp\n",
       "2998      0  The whole experience was underwhelming, and I ...    yelp\n",
       "2999      0  Then, as if I hadn't wasted enough of my life ...    yelp\n",
       "\n",
       "[3000 rows x 3 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>puncs</th>\n",
       "      <th>uppers</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>82</td>\n",
       "      <td>21</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>7.181818</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  source  chars  \\\n",
       "0      0  So there is no way for me to plug it in here i...  amazon     82   \n",
       "1      1                        Good case, Excellent value.  amazon     27   \n",
       "2      1                             Great for the jawbone.  amazon     22   \n",
       "3      0  Tied to charger for conversations lasting more...  amazon     79   \n",
       "4      1                                  The mic is great.  amazon     17   \n",
       "\n",
       "   words  avg_wlen  puncs  uppers  titles  \n",
       "0     21  3.904762      1      21      21  \n",
       "1      4  6.750000      2       4       4  \n",
       "2      4  5.500000      1       4       4  \n",
       "3     11  7.181818      3      11      11  \n",
       "4      4  4.250000      1       4       4  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import string\n",
    "df['chars'] = df.text.apply(len)\n",
    "df['words'] = df.text.apply(lambda x: len(x.split()))\n",
    "df['avg_wlen'] = df['chars']/ df['words']\n",
    "df['puncs'] = df.text.apply(lambda x: len(\"\".join(_ for _ in x if _ in string.punctuation)))\n",
    "df['uppers'] = df.text.apply(lambda x: len([word for word in x.split() if word.isupper]))\n",
    "df['titles'] = df.text.apply(lambda x: len([word for word in x.split() if word.istitle]))\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0        82\n",
       "1        27\n",
       "2        22\n",
       "3        79\n",
       "4        17\n",
       "       ... \n",
       "2995     66\n",
       "2996     24\n",
       "2997     50\n",
       "2998     91\n",
       "2999    134\n",
       "Name: text, Length: 3000, dtype: int64"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].str.len()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "The food was terrible.                                                                                         2\n",
       "Don't buy this product.                                                                                        2\n",
       "If you like a loud buzzing to override all your conversations, then this phone is for you!                     2\n",
       "Not recommended.                                                                                               2\n",
       "I would not recommend this place.                                                                              2\n",
       "                                                                                                              ..\n",
       "\" But \"Storm Trooper\" is not even bad enough to make it to the list of wonderfully terrible movies.            1\n",
       "What happened next was pretty....off putting.                                                                  1\n",
       "The headsets are easy to use and everyone loves them.                                                          1\n",
       "It only recognizes the Phone as its storage device.                                                            1\n",
       "As a courtroom drama, it's compelling, as an indictment on the American justice system, it's frightening.      1\n",
       "Name: text, Length: 2983, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['So there is no way for me to plug it in here in the US unless I go by a converter.',\n",
       "       'Good case, Excellent value.', 'Great for the jawbone.', ...,\n",
       "       'Overall I was not impressed and would not go back.',\n",
       "       \"The whole experience was underwhelming, and I think we'll just go to Ninja Sushi next time.\",\n",
       "       \"Then, as if I hadn't wasted enough of my life there, they poured salt in the wound by drawing out the time it took to bring the check.\"],\n",
       "      dtype=object)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['text'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7\n",
      "479\n"
     ]
    }
   ],
   "source": [
    "print(min(df['text'].str.len()))\n",
    "print(max(df['text'].str.len()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vectorize = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_df = count_vectorize.fit(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_df = feature_vector_df.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "df total number of unique words: 5159\n"
     ]
    }
   ],
   "source": [
    "print('df total number of unique words:', len(features_df))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['venture',\n",
       " 'interest',\n",
       " 'half',\n",
       " 'key',\n",
       " 'elias',\n",
       " 'eating',\n",
       " 'fifteen',\n",
       " 'considerable',\n",
       " 'tolerable',\n",
       " 'monolog']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "random.sample(features_df, 10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "feature_vector_df_transform = count_vectorize.transform(df.text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "scipy.sparse.csr.csr_matrix"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(feature_vector_df_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "31580"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "feature_vector_df_transform.getnnz()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Density of the matrix:  0.20404471150739809\n"
     ]
    }
   ],
   "source": [
    "print(\"Density of the matrix: \", feature_vector_df_transform.getnnz()*100/(feature_vector_df_transform.shape[0]*feature_vector_df_transform.shape[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = pd.DataFrame(feature_vector_df_transform.todense())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.columns = features_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>00</th>\n",
       "      <th>10</th>\n",
       "      <th>100</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>15</th>\n",
       "      <th>15g</th>\n",
       "      <th>15pm</th>\n",
       "      <th>17</th>\n",
       "      <th>...</th>\n",
       "      <th>yucky</th>\n",
       "      <th>yukon</th>\n",
       "      <th>yum</th>\n",
       "      <th>yummy</th>\n",
       "      <th>yun</th>\n",
       "      <th>z500a</th>\n",
       "      <th>zero</th>\n",
       "      <th>zillion</th>\n",
       "      <th>zombie</th>\n",
       "      <th>zombiez</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1 rows × 5159 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   00  10  100  11  12  13  15  15g  15pm  17  ...  yucky  yukon  yum  yummy  \\\n",
       "0   0   0    0   0   0   0   0    0     0   0  ...      0      0    0      0   \n",
       "\n",
       "   yun  z500a  zero  zillion  zombie  zombiez  \n",
       "0    0      0     0        0       0        0  \n",
       "\n",
       "[1 rows x 5159 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    So there is no way for me to plug it in here i...\n",
       "Name: text, dtype: object"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.text[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count = np.sum(feature_vector_df_transform.toarray(), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "features_count_df = pd.DataFrame(dict(features_df=features_df, counts= features_count))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([5.112e+03, 2.700e+01, 8.000e+00, 3.000e+00, 1.000e+00, 1.000e+00,\n",
       "        3.000e+00, 2.000e+00, 0.000e+00, 0.000e+00]),\n",
       " array([   0.,  100.,  200.,  300.,  400.,  500.,  600.,  700.,  800.,\n",
       "         900., 1000.]),\n",
       " <BarContainer object of 10 artists>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 576x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure(figsize=(8,6))\n",
    "plt.xlabel('Frequency of words')\n",
    "plt.ylabel('Density')\n",
    "plt.hist(features_count_df.counts, bins=10, range=(0,1000))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2922"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(features_count_df[features_count_df.counts==1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>features</th>\n",
       "      <th>counts</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2377</th>\n",
       "      <td>the</td>\n",
       "      <td>1953</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>85</th>\n",
       "      <td>and</td>\n",
       "      <td>1138</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1036</th>\n",
       "      <td>it</td>\n",
       "      <td>789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1033</th>\n",
       "      <td>is</td>\n",
       "      <td>753</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2455</th>\n",
       "      <td>to</td>\n",
       "      <td>670</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2404</th>\n",
       "      <td>this</td>\n",
       "      <td>643</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1334</th>\n",
       "      <td>of</td>\n",
       "      <td>624</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2814</th>\n",
       "      <td>was</td>\n",
       "      <td>571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1005</th>\n",
       "      <td>in</td>\n",
       "      <td>400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>801</th>\n",
       "      <td>for</td>\n",
       "      <td>336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2375</th>\n",
       "      <td>that</td>\n",
       "      <td>316</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1315</th>\n",
       "      <td>not</td>\n",
       "      <td>306</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2915</th>\n",
       "      <td>with</td>\n",
       "      <td>274</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1281</th>\n",
       "      <td>my</td>\n",
       "      <td>254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2736</th>\n",
       "      <td>very</td>\n",
       "      <td>245</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     features  counts\n",
       "2377      the    1953\n",
       "85        and    1138\n",
       "1036       it     789\n",
       "1033       is     753\n",
       "2455       to     670\n",
       "2404     this     643\n",
       "1334       of     624\n",
       "2814      was     571\n",
       "1005       in     400\n",
       "801       for     336\n",
       "2375     that     316\n",
       "1315      not     306\n",
       "2915     with     274\n",
       "1281       my     254\n",
       "2736     very     245"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "count_vectorizer = CountVectorizer(max_features=3000)\n",
    "feature_vector = count_vectorizer.fit(df.text)\n",
    "features = feature_vector.get_feature_names()\n",
    "train_ds_features = count_vectorizer.transform(df.text)\n",
    "features_counts = np.sum(train_ds_features.toarray(),axis=0)\n",
    "features_counts = pd.DataFrame(dict(features= features, counts = features_counts))\n",
    "features_counts.sort_values('counts', ascending=False)[0:15]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "few stop words: ['but', 'couldnt', 'whence', 'top', 'or', 'to', 'already', 'indeed', 'some', 'their', 'than', 'thick', 'nine', 'i', 'them', 'myself', 'any', 'thus', 'down', 'alone', 'whereupon', 'beforehand', 'themselves', 'an', 'other', 'by', 'six', 'rather', 'amongst', 'two', 'almost', 'keep', 'whose', 'between', 'throughout', 'seemed', 'meanwhile', 'here', 'nevertheless', 'nobody', 'sometime', 'she', 'anyway', 'forty', 'itself', 'whereafter', 'done', 'thin', 'even', 'eg', 'anyhow', 'see', 'sixty', 'either', 'though', 'no', 'via', 'one', 'least', 'where', 'yours', 'across', 'this', 'sometimes', 'such', 'has', 'due', 'three', 'un', 'then', 'bottom', 'with', 'ltd', 'latter', 'fill', 'beyond', 'may', 'because', 'as', 'twenty', 'cannot', 'too', 'do', 'have', 'yet', 'noone', 'etc', 'against', 'same', 'whoever', 'enough', 'latterly', 'became', 'together', 'for', 'which', 'after', 'if', 'made', 'you', 'can', 'side', 're', 'eight', 'what', 'thru', 'will', 'himself', 'is', 'a', 'co', 'under', 'above', 'when', 'seems', 'whereas', 'several', 'never', 'her', 'mostly', 'once', 'fifteen', 'he', 'and', 'whatever', 'next', 'him', 'often', 'put', 'show', 'anyone', 'de', 'be', 'might', 'at', 'there', 'own', 'empty', 'thence', 'our', 'none', 'five', 'otherwise', 'less', 'over', 'mill', 'are', 'were', 'my', 'in', 'move', 'fire', 'become', 'hereupon', 'everything', 'thereafter', 'found', 'now', 'afterwards', 'back', 'although', 'during', 'namely', 'it', 'nothing', 'around', 'whenever', 'full', 'former', 'ourselves', 'they', 'besides', 'its', 'us', 'wherever', 'onto', 'among', 'perhaps', 'thereby', 'amoungst', 'first', 'few', 'along', 'wherein', 'interest', 'also', 'therefore', 'nor', 'out', 'hundred', 'had', 'mine', 'formerly', 'am', 'elsewhere', 'seeming', 'yourself', 'hereby', 'ever', 'inc', 'would', 'find', 'somehow', 'about', 'very', 'thereupon', 'cant', 'part', 'who', 'until', 'within', 'give', 'fifty', 'system', 'while', 'whereby', 'else', 'except', 'so', 'third', 'before', 'yourselves', 'both', 'beside', 'below', 'must', 'was', 'each', 'name', 'how', 'those', 'why', 'sincere', 'still', 'becomes', 'herein', 'con', 'herself', 'me', 'hasnt', 'everyone', 'since', 'seem', 'ie', 'into', 'upon', 'neither', 'more', 'hers', 'behind', 'get', 'everywhere', 'most', 'toward', 'your', 'go', 'amount', 'whom', 'therein', 'whether', 'eleven', 'we', 'whole', 'the', 'many', 'someone', 'on', 'detail', 'call', 'should', 'front', 'hence', 'without', 'per', 'twelve', 'always', 'that', 'been', 'others', 'ours', 'being', 'something', 'only', 'take', 'much', 'cry', 'serious', 'all', 'please', 'becoming', 'anything', 'through', 'somewhere', 'of', 'could', 'four', 'hereafter', 'whither', 'up', 'his', 'from', 'anywhere', 'moreover', 'well', 'however', 'further', 'another', 'ten', 'towards', 'describe', 'last', 'nowhere', 'again', 'not', 'bill', 'these', 'off', 'every']\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text\n",
    "my_stop_words = text.ENGLISH_STOP_WORDS\n",
    "print('few stop words:', list(my_stop_words)[0:400])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='awesome'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_ds_features.todense())\n",
    "train_df.columns=features\n",
    "train_df['label']=df.label\n",
    "sns.barplot(x='label',y='awesome',data=train_df, estimator=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='label', ylabel='hate'>"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAEGCAYAAABiq/5QAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjMuMiwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8vihELAAAACXBIWXMAAAsTAAALEwEAmpwYAAANB0lEQVR4nO3dfYxld13H8feH3Ta4LbSQDi12u0xFXAK1CXSiFhIMlOoqFXzoHzSgFRr3D1HQqBUCyF8aLfgUNZgVais0JaZgSkwEmio0aK3OtqUPLAgpUHbpurMhSqkPbcPXP+bWLNMZ9nbbc852vu9X0szcc+7O75tm856Tc+/9baoKSVIfT5l6AEnSuAy/JDVj+CWpGcMvSc0YfklqZuvUA8zjtNNOq8XFxanHkKQnlb179x6uqoW1x58U4V9cXGR5eXnqMSTpSSXJV9Y77q0eSWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1M1j4k1yZ5FCSu9Y59+tJKslpQ60vSVrfkFf8VwG71h5MchZwIXDvgGtLkjYw2Ae4quqmJIvrnPpD4HLg+qHW1sYuv/xyDh48yBlnnMEVV1wx9TiSJjDqJ3eTvBo4UFWfSXK05+4GdgPs2LFjhOl6OHjwIAcOHJh6DEkTGu3F3STbgLcDvzXP86tqT1UtVdXSwsKjtpqQJB2jMd/V81zgbOAzSb4MbAduTXLGiDNIUnuj3eqpqjuBZz3yeBb/pao6PNYMkqRh3855LXAzsDPJ/iSXDbWWJGl+Q76r55KjnF8cam1J0sb85K4kNWP4JakZwy9JzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqZrDwJ7kyyaEkdx1x7N1JPpfkjiR/k+TUodaXJK1vyCv+q4Bda47dAJxTVecC/wa8bcD1JUnrGCz8VXUT8PU1xz5RVQ/PHv4zsH2o9SVJ65vyHv8bgb/b6GSS3UmWkyyvrKyMOJYkbW6ThD/J24GHgWs2ek5V7amqpapaWlhYGG84Sdrkto69YJJLgYuAC6qqxl5fkrobNfxJdgG/CfxwVf3XmGtLklYN+XbOa4GbgZ1J9ie5DPhT4GnADUluT/LnQ60vSVrfYFf8VXXJOoffP9R6kqT5+MldSWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmBgt/kiuTHEpy1xHHnpnkhiRfmH19xlDrS5LWN+QV/1XArjXH3grcWFXPA26cPZYkjWiw8FfVTcDX1xx+DXD17PurgZ8can1J0vrGvsd/elXdBzD7+qyNnphkd5LlJMsrKyujDShJm91x++JuVe2pqqWqWlpYWJh6HEnaNMYO/78neTbA7OuhkdeXpPbGDv9HgUtn318KXD/y+pLU3pBv57wWuBnYmWR/ksuA3wUuTPIF4MLZY0nSiLYO9YOr6pINTl0w1JqSpKM7bl/clSQNw/BLUjOGX5KaMfyS1Izhl6RmDL8kNWP4JakZwy9JzRh+SWrG8EtSM4Zfkpox/JLUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktTMJOFP8qtJ7k5yV5Jrkzx1ijkkqaPRw5/kTODNwFJVnQNsAV479hyS1NVUt3q2At+VZCuwDfjaRHNIUjtbx16wqg4keQ9wL/DfwCeq6hNrn5dkN7AbYMeOHY973fN+468e98/YDJ52+H62APcevt//J8Ded//c1CNIo5viVs8zgNcAZwPfDZyU5PVrn1dVe6pqqaqWFhYWxh5TkjatucKf5PuS3Jjkrtnjc5O84xjXfCXwpapaqaqHgI8ALznGnyVJeozmveL/C+BtwEMAVXUHx/6C7L3ADyXZliTABcC+Y/xZkqTHaN7wb6uqf1lz7OFjWbCqbgGuA24F7pzNsOdYfpYk6bGb98Xdw0meCxRAkouB+4510ap6F/CuY/3zkqRjN2/438TqVfnzkxwAvgS8brCpJEmDmTf8VVWvTHIS8JSquj/J2UMOJkkaxrz3+D8MUFUPVNX9s2PXDTOSJGlI3/GKP8nzgRcCpyT56SNOPR1wfx1JehI62q2encBFwKnATxxx/H7gFwaaSZI0oO8Y/qq6Hrg+yflVdfNIM0mSBjTvi7u3JXkTq7d9/v8WT1W9cZCpJEmDmffF3Q8AZwA/CnwK2M7q7R5J0pPMvOH/3qp6J/BAVV0NvAr4/uHGkiQNZd7wPzT7+h9JzgFOARYHmUiSNKh57/HvmW2n/A7go8DJwDsHm0qSNJh5w/8B4GdYvcq/enbs9CEGkiQNa97wXw/8J7AX+N/hxpEkDW3e8G+vql2DTiJJGsW8L+7+UxLfxSNJm8DR9uq5k9U9+LcCb0hyD6u3esLqjp3nDj+iJOmJdLRbPReNMoUkaTRH26vnK2MNIkkax7z3+CVJm4Thl6RmDL8kNTNJ+JOcmuS6JJ9Lsi/J+VPMIUkdzfsBrifaHwMfq6qLk5wIbJtoDklqZ/TwJ3k68DLg5wGq6kHgwbHnkKSuprjV8z3ACvCXSW5L8r4kJ619UpLdSZaTLK+srIw/pSRtUlOEfyvwYuC9VfUi4AHgrWufVFV7qmqpqpYWFhbGnlGSNq0pwr8f2F9Vt8weX8fqLwJJ0ghGD39VHQS+mmTn7NAFwGfHnkOSuprqXT2/DFwze0fPPcAbJppDktqZJPxVdTuwNMXaktSdn9yVpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmDL8kNWP4JakZwy9JzUwW/iRbktyW5G+nmkGSOpryiv8twL4J15ekliYJf5LtwKuA902xviR1NtUV/x8BlwPfmmh9SWpr9PAnuQg4VFV7j/K83UmWkyyvrKyMNJ0kbX5TXPG/FHh1ki8DHwJekeSDa59UVXuqaqmqlhYWFsaeUZI2rdHDX1Vvq6rtVbUIvBb4+6p6/dhzSFJXvo9fkprZOuXiVfVJ4JNTziBJ3XjFL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqZtItGzS+b5140rd9ldSP4W/mgef9yNQjSJqYt3okqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpmdHDn+SsJP+QZF+Su5O8ZewZJKmzKbZseBj4taq6NcnTgL1Jbqiqz04wiyS1M/oVf1XdV1W3zr6/H9gHnDn2HJLU1aT3+JMsAi8Cblnn3O4ky0mWV1ZWRp9NkjarycKf5GTgw8CvVNU31p6vqj1VtVRVSwsLC+MPKEmb1CThT3ICq9G/pqo+MsUMktTVFO/qCfB+YF9V/cHY60tSd1Nc8b8U+FngFUlun/334xPMIUktjf52zqr6NJCx15UkrfKTu5LUjOGXpGYMvyQ1Y/glqRnDL0nNGH5JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpGcMvSc0YfklqxvBLUjOGX5KaMfyS1Izhl6RmDL8kNWP4JakZwy9JzUwS/iS7knw+yReTvHWKGSSpq9HDn2QL8GfAjwEvAC5J8oKx55Ckrqa44v8B4ItVdU9VPQh8CHjNBHNIUktbJ1jzTOCrRzzeD/zg2icl2Q3snj38ZpLPjzBbF6cBh6ce4niQ91w69Qj6dv7dfGI9Z72DU4Q/6xyrRx2o2gPsGX6cfpIsV9XS1HNIa/l3cxxT3OrZD5x1xOPtwNcmmEOSWpoi/P8KPC/J2UlOBF4LfHSCOSSppdFv9VTVw0l+Cfg4sAW4sqruHnuO5ryFpuOVfzdHkKpH3V6XJG1ifnJXkpox/JLUjOFvxK0ydLxKcmWSQ0numnqWDgx/E26VoePcVcCuqYfowvD34VYZOm5V1U3A16eeowvD38d6W2WcOdEskiZk+PuYa6sMSZuf4e/DrTIkAYa/E7fKkAQY/jaq6mHgka0y9gF/7VYZOl4kuRa4GdiZZH+Sy6aeaTNzywZJasYrfklqxvBLUjOGX5KaMfyS1Izhl6RmDL+0RpJvHuX84mPdRTLJVUkufnyTSU8Mwy9JzRh+aQNJTk5yY5Jbk9yZ5MjdTLcmuTrJHUmuS7Jt9mfOS/KpJHuTfDzJsycaX9qQ4Zc29j/AT1XVi4GXA7+f5JHN7nYCe6rqXOAbwC8mOQH4E+DiqjoPuBL47Qnmlr6jrVMPIB3HAvxOkpcB32J1G+vTZ+e+WlX/OPv+g8CbgY8B5wA3zH4/bAHuG3ViaQ6GX9rY64AF4LyqeijJl4Gnzs6t3eukWP1FcXdVnT/eiNJj560eaWOnAIdm0X858Jwjzu1I8kjgLwE+DXweWHjkeJITkrxw1ImlORh+aWPXAEtJllm9+v/cEef2AZcmuQN4JvDe2T9peTHwe0k+A9wOvGTckaWjc3dOSWrGK35JasbwS1Izhl+SmjH8ktSM4ZekZgy/JDVj+CWpmf8Dd9Ky2leUBqoAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "train_df = pd.DataFrame(train_ds_features.todense())\n",
    "train_df.columns=features\n",
    "train_df['label']=df.label\n",
    "sns.barplot(x='label',y='hate',data=train_df, estimator=sum)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>puncs</th>\n",
       "      <th>uppers</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>82</td>\n",
       "      <td>21</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>7.181818</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>yelp</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>91</td>\n",
       "      <td>16</td>\n",
       "      <td>5.687500</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>134</td>\n",
       "      <td>28</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  source  chars  \\\n",
       "0         0  So there is no way for me to plug it in here i...  amazon     82   \n",
       "1         1                        Good case, Excellent value.  amazon     27   \n",
       "2         1                             Great for the jawbone.  amazon     22   \n",
       "3         0  Tied to charger for conversations lasting more...  amazon     79   \n",
       "4         1                                  The mic is great.  amazon     17   \n",
       "...     ...                                                ...     ...    ...   \n",
       "2995      0  I think food should have flavor and texture an...    yelp     66   \n",
       "2996      0                           Appetite instantly gone.    yelp     24   \n",
       "2997      0  Overall I was not impressed and would not go b...    yelp     50   \n",
       "2998      0  The whole experience was underwhelming, and I ...    yelp     91   \n",
       "2999      0  Then, as if I hadn't wasted enough of my life ...    yelp    134   \n",
       "\n",
       "      words  avg_wlen  puncs  uppers  titles  \n",
       "0        21  3.904762      1      21      21  \n",
       "1         4  6.750000      2       4       4  \n",
       "2         4  5.500000      1       4       4  \n",
       "3        11  7.181818      3      11      11  \n",
       "4         4  4.250000      1       4       4  \n",
       "...     ...       ...    ...     ...     ...  \n",
       "2995     12  5.500000      1      12      12  \n",
       "2996      3  8.000000      1       3       3  \n",
       "2997     10  5.000000      1      10      10  \n",
       "2998     16  5.687500      3      16      16  \n",
       "2999     28  4.785714      4      28      28  \n",
       "\n",
       "[3000 rows x 9 columns]"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"2\" halign=\"left\">chars</th>\n",
       "      <th colspan=\"2\" halign=\"left\">words</th>\n",
       "      <th colspan=\"2\" halign=\"left\">avg_wlen</th>\n",
       "      <th colspan=\"2\" halign=\"left\">puncs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">uppers</th>\n",
       "      <th colspan=\"2\" halign=\"left\">titles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "      <th>mean</th>\n",
       "      <th>std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>0</td>\n",
       "      <td>56.824</td>\n",
       "      <td>34.022464</td>\n",
       "      <td>10.578</td>\n",
       "      <td>6.578028</td>\n",
       "      <td>5.653474</td>\n",
       "      <td>1.262250</td>\n",
       "      <td>2.002</td>\n",
       "      <td>1.509488</td>\n",
       "      <td>10.578</td>\n",
       "      <td>6.578028</td>\n",
       "      <td>10.578</td>\n",
       "      <td>6.578028</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>1</td>\n",
       "      <td>53.628</td>\n",
       "      <td>35.234764</td>\n",
       "      <td>9.914</td>\n",
       "      <td>6.785772</td>\n",
       "      <td>5.670933</td>\n",
       "      <td>1.113802</td>\n",
       "      <td>1.842</td>\n",
       "      <td>1.296301</td>\n",
       "      <td>9.914</td>\n",
       "      <td>6.785772</td>\n",
       "      <td>9.914</td>\n",
       "      <td>6.785772</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb</td>\n",
       "      <td>0</td>\n",
       "      <td>77.104</td>\n",
       "      <td>50.901504</td>\n",
       "      <td>13.580</td>\n",
       "      <td>9.037863</td>\n",
       "      <td>5.814498</td>\n",
       "      <td>0.941015</td>\n",
       "      <td>2.494</td>\n",
       "      <td>1.954893</td>\n",
       "      <td>13.580</td>\n",
       "      <td>9.037863</td>\n",
       "      <td>13.580</td>\n",
       "      <td>9.037863</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>87.466</td>\n",
       "      <td>60.831157</td>\n",
       "      <td>15.128</td>\n",
       "      <td>10.102859</td>\n",
       "      <td>5.826946</td>\n",
       "      <td>0.992992</td>\n",
       "      <td>2.650</td>\n",
       "      <td>2.282525</td>\n",
       "      <td>15.128</td>\n",
       "      <td>10.102859</td>\n",
       "      <td>15.128</td>\n",
       "      <td>10.102859</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yelp</td>\n",
       "      <td>0</td>\n",
       "      <td>60.752</td>\n",
       "      <td>34.226443</td>\n",
       "      <td>11.498</td>\n",
       "      <td>6.611916</td>\n",
       "      <td>5.401394</td>\n",
       "      <td>0.896878</td>\n",
       "      <td>2.000</td>\n",
       "      <td>1.424098</td>\n",
       "      <td>11.498</td>\n",
       "      <td>6.611916</td>\n",
       "      <td>11.498</td>\n",
       "      <td>6.611916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yelp</td>\n",
       "      <td>1</td>\n",
       "      <td>55.888</td>\n",
       "      <td>30.232490</td>\n",
       "      <td>10.290</td>\n",
       "      <td>5.831459</td>\n",
       "      <td>5.606887</td>\n",
       "      <td>0.951414</td>\n",
       "      <td>1.930</td>\n",
       "      <td>1.658494</td>\n",
       "      <td>10.290</td>\n",
       "      <td>5.831459</td>\n",
       "      <td>10.290</td>\n",
       "      <td>5.831459</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source label   chars              words             avg_wlen            \\\n",
       "                   mean        std    mean        std      mean       std   \n",
       "0  amazon     0  56.824  34.022464  10.578   6.578028  5.653474  1.262250   \n",
       "1  amazon     1  53.628  35.234764   9.914   6.785772  5.670933  1.113802   \n",
       "2    imdb     0  77.104  50.901504  13.580   9.037863  5.814498  0.941015   \n",
       "3    imdb     1  87.466  60.831157  15.128  10.102859  5.826946  0.992992   \n",
       "4    yelp     0  60.752  34.226443  11.498   6.611916  5.401394  0.896878   \n",
       "5    yelp     1  55.888  30.232490  10.290   5.831459  5.606887  0.951414   \n",
       "\n",
       "   puncs            uppers             titles             \n",
       "    mean       std    mean        std    mean        std  \n",
       "0  2.002  1.509488  10.578   6.578028  10.578   6.578028  \n",
       "1  1.842  1.296301   9.914   6.785772   9.914   6.785772  \n",
       "2  2.494  1.954893  13.580   9.037863  13.580   9.037863  \n",
       "3  2.650  2.282525  15.128  10.102859  15.128  10.102859  \n",
       "4  2.000  1.424098  11.498   6.611916  11.498   6.611916  \n",
       "5  1.930  1.658494  10.290   5.831459  10.290   5.831459  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>source</th>\n",
       "      <th>label</th>\n",
       "      <th colspan=\"2\" halign=\"left\">chars</th>\n",
       "      <th colspan=\"2\" halign=\"left\">words</th>\n",
       "      <th colspan=\"2\" halign=\"left\">avg_wlen</th>\n",
       "      <th colspan=\"2\" halign=\"left\">puncs</th>\n",
       "      <th colspan=\"2\" halign=\"left\">uppers</th>\n",
       "      <th colspan=\"2\" halign=\"left\">titles</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "      <th>min</th>\n",
       "      <th>max</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>amazon</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.857143</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>amazon</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>3.166667</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>30.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>imdb</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>321.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>4.181818</td>\n",
       "      <td>11.5</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>56.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>imdb</td>\n",
       "      <td>1</td>\n",
       "      <td>7.0</td>\n",
       "      <td>479.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>3.200000</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>71.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>yelp</td>\n",
       "      <td>0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>149.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>12.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>yelp</td>\n",
       "      <td>1</td>\n",
       "      <td>11.0</td>\n",
       "      <td>148.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>3.666667</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>32.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   source label chars        words        avg_wlen       puncs       uppers  \\\n",
       "                  min    max   min   max       min   max   min   max    min   \n",
       "0  amazon     0  11.0  149.0   1.0  30.0  3.857143  14.0   0.0  11.0    1.0   \n",
       "1  amazon     1  11.0  148.0   1.0  30.0  3.166667  13.0   0.0   9.0    1.0   \n",
       "2    imdb     0   8.0  321.0   1.0  56.0  4.181818  11.5   1.0  14.0    1.0   \n",
       "3    imdb     1   7.0  479.0   1.0  71.0  3.200000  12.0   0.0  18.0    1.0   \n",
       "4    yelp     0  11.0  149.0   2.0  32.0  3.666667  12.5   0.0  11.0    2.0   \n",
       "5    yelp     1  11.0  148.0   1.0  32.0  3.666667  11.0   0.0  19.0    1.0   \n",
       "\n",
       "        titles        \n",
       "    max    min   max  \n",
       "0  30.0    1.0  30.0  \n",
       "1  30.0    1.0  30.0  \n",
       "2  56.0    1.0  56.0  \n",
       "3  71.0    1.0  71.0  \n",
       "4  32.0    2.0  32.0  \n",
       "5  32.0    1.0  32.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df.groupby(['source', 'label']).describe().loc[:,(slice(None),['mean', 'std'])].reset_index())\n",
    "display(df.groupby(['source', 'label']).describe().loc[:,(slice(None),['min', 'max'])].reset_index())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>puncs</th>\n",
       "      <th>uppers</th>\n",
       "      <th>titles</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>82</td>\n",
       "      <td>21</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>7.181818</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2995</th>\n",
       "      <td>0</td>\n",
       "      <td>I think food should have flavor and texture an...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>66</td>\n",
       "      <td>12</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>12</td>\n",
       "      <td>12</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2996</th>\n",
       "      <td>0</td>\n",
       "      <td>Appetite instantly gone.</td>\n",
       "      <td>yelp</td>\n",
       "      <td>24</td>\n",
       "      <td>3</td>\n",
       "      <td>8.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2997</th>\n",
       "      <td>0</td>\n",
       "      <td>Overall I was not impressed and would not go b...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>50</td>\n",
       "      <td>10</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>1</td>\n",
       "      <td>10</td>\n",
       "      <td>10</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2998</th>\n",
       "      <td>0</td>\n",
       "      <td>The whole experience was underwhelming, and I ...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>91</td>\n",
       "      <td>16</td>\n",
       "      <td>5.687500</td>\n",
       "      <td>3</td>\n",
       "      <td>16</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2999</th>\n",
       "      <td>0</td>\n",
       "      <td>Then, as if I hadn't wasted enough of my life ...</td>\n",
       "      <td>yelp</td>\n",
       "      <td>134</td>\n",
       "      <td>28</td>\n",
       "      <td>4.785714</td>\n",
       "      <td>4</td>\n",
       "      <td>28</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3000 rows × 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      label                                               text  source  chars  \\\n",
       "0         0  So there is no way for me to plug it in here i...  amazon     82   \n",
       "1         1                        Good case, Excellent value.  amazon     27   \n",
       "2         1                             Great for the jawbone.  amazon     22   \n",
       "3         0  Tied to charger for conversations lasting more...  amazon     79   \n",
       "4         1                                  The mic is great.  amazon     17   \n",
       "...     ...                                                ...     ...    ...   \n",
       "2995      0  I think food should have flavor and texture an...    yelp     66   \n",
       "2996      0                           Appetite instantly gone.    yelp     24   \n",
       "2997      0  Overall I was not impressed and would not go b...    yelp     50   \n",
       "2998      0  The whole experience was underwhelming, and I ...    yelp     91   \n",
       "2999      0  Then, as if I hadn't wasted enough of my life ...    yelp    134   \n",
       "\n",
       "      words  avg_wlen  puncs  uppers  titles  \n",
       "0        21  3.904762      1      21      21  \n",
       "1         4  6.750000      2       4       4  \n",
       "2         4  5.500000      1       4       4  \n",
       "3        11  7.181818      3      11      11  \n",
       "4         4  4.250000      1       4       4  \n",
       "...     ...       ...    ...     ...     ...  \n",
       "2995     12  5.500000      1      12      12  \n",
       "2996      3  8.000000      1       3       3  \n",
       "2997     10  5.000000      1      10      10  \n",
       "2998     16  5.687500      3      16      16  \n",
       "2999     28  4.785714      4      28      28  \n",
       "\n",
       "[3000 rows x 9 columns]"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal for tokenization is to prepare the text data for machine learning. It can clean the text by removing stopwords, puncutations. it characterizes words to a unique token to be classified by splitting the sentence into indiviual words."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-37-46564b2a546f>:16: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df['clean_text'][i] = ' '.join(words)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>puncs</th>\n",
       "      <th>uppers</th>\n",
       "      <th>titles</th>\n",
       "      <th>clean_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>82</td>\n",
       "      <td>21</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>amazon way plug us unless go converter</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon good case excellent value</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon great jawbone</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>7.181818</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>amazon tied charger conversations lasting 45 m...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon mic great</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  source  chars  \\\n",
       "0      0  So there is no way for me to plug it in here i...  amazon     82   \n",
       "1      1                        Good case, Excellent value.  amazon     27   \n",
       "2      1                             Great for the jawbone.  amazon     22   \n",
       "3      0  Tied to charger for conversations lasting more...  amazon     79   \n",
       "4      1                                  The mic is great.  amazon     17   \n",
       "\n",
       "   words  avg_wlen  puncs  uppers  titles  \\\n",
       "0     21  3.904762      1      21      21   \n",
       "1      4  6.750000      2       4       4   \n",
       "2      4  5.500000      1       4       4   \n",
       "3     11  7.181818      3      11      11   \n",
       "4      4  4.250000      1       4       4   \n",
       "\n",
       "                                          clean_text  \n",
       "0             amazon way plug us unless go converter  \n",
       "1                   amazon good case excellent value  \n",
       "2                               amazon great jawbone  \n",
       "3  amazon tied charger conversations lasting 45 m...  \n",
       "4                                   amazon mic great  "
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords\n",
    "import string\n",
    "\n",
    "i=0\n",
    "df['clean_text'] = ''\n",
    "for row in df.text:\n",
    "    row = row.replace('.','. ', row.count('.')).replace(',', ', ', row.count(','))\n",
    "    tokens = word_tokenize(row)\n",
    "    tokens = [token.lower() for token in tokens]\n",
    "    table = str.maketrans('', '', string.punctuation)\n",
    "    words = [token.translate(table) for token in tokens]\n",
    "    words = [word for word in words if word.isalnum()]\n",
    "    stop_words = set(stopwords.words('english'))\n",
    "    words = [word for word in words if not word in stop_words]\n",
    "    df['clean_text'][i] = ' '.join(words)\n",
    "    i += 1\n",
    "df.clean_text = df.source + ' ' + df.clean_text\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "df['clean_words'] = df.clean_text.apply(lambda x: len(x.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>label</th>\n",
       "      <th>text</th>\n",
       "      <th>source</th>\n",
       "      <th>chars</th>\n",
       "      <th>words</th>\n",
       "      <th>avg_wlen</th>\n",
       "      <th>puncs</th>\n",
       "      <th>uppers</th>\n",
       "      <th>titles</th>\n",
       "      <th>clean_text</th>\n",
       "      <th>clean_words</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>So there is no way for me to plug it in here i...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>82</td>\n",
       "      <td>21</td>\n",
       "      <td>3.904762</td>\n",
       "      <td>1</td>\n",
       "      <td>21</td>\n",
       "      <td>21</td>\n",
       "      <td>amazon way plug us unless go converter</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>Good case, Excellent value.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>27</td>\n",
       "      <td>4</td>\n",
       "      <td>6.750000</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon good case excellent value</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>Great for the jawbone.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>22</td>\n",
       "      <td>4</td>\n",
       "      <td>5.500000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon great jawbone</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>Tied to charger for conversations lasting more...</td>\n",
       "      <td>amazon</td>\n",
       "      <td>79</td>\n",
       "      <td>11</td>\n",
       "      <td>7.181818</td>\n",
       "      <td>3</td>\n",
       "      <td>11</td>\n",
       "      <td>11</td>\n",
       "      <td>amazon tied charger conversations lasting 45 m...</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>The mic is great.</td>\n",
       "      <td>amazon</td>\n",
       "      <td>17</td>\n",
       "      <td>4</td>\n",
       "      <td>4.250000</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>4</td>\n",
       "      <td>amazon mic great</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   label                                               text  source  chars  \\\n",
       "0      0  So there is no way for me to plug it in here i...  amazon     82   \n",
       "1      1                        Good case, Excellent value.  amazon     27   \n",
       "2      1                             Great for the jawbone.  amazon     22   \n",
       "3      0  Tied to charger for conversations lasting more...  amazon     79   \n",
       "4      1                                  The mic is great.  amazon     17   \n",
       "\n",
       "   words  avg_wlen  puncs  uppers  titles  \\\n",
       "0     21  3.904762      1      21      21   \n",
       "1      4  6.750000      2       4       4   \n",
       "2      4  5.500000      1       4       4   \n",
       "3     11  7.181818      3      11      11   \n",
       "4      4  4.250000      1       4       4   \n",
       "\n",
       "                                          clean_text  clean_words  \n",
       "0             amazon way plug us unless go converter            7  \n",
       "1                   amazon good case excellent value            5  \n",
       "2                               amazon great jawbone            3  \n",
       "3  amazon tied charger conversations lasting 45 m...            9  \n",
       "4                                   amazon mic great            3  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n",
      "42\n"
     ]
    }
   ],
   "source": [
    "print(min(df['clean_words']))\n",
    "print(max(df['clean_words']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "B3"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The padding process works by setting a max length of words and any words short of  the max word length will get additional zeroes in place to meet the max length. Any sentence over the max will get words droppped to meet the max as well. This is neccessary for NLP to work by having the same inputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import pad_sequences\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "tokenizer = Tokenizer(num_words=50)\n",
    "sequences=tokenizer.texts_to_sequences(df.text)\n",
    "padded=pad_sequences(sequences, padding=\"pre\",truncating='pre',maxlen=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(df.clean_text, df.label) \n",
    "\n",
    "# label encode the target \n",
    "encoder = preprocessing.LabelEncoder()\n",
    "y_train = encoder.fit_transform(y_train)\n",
    "y_test = encoder.fit_transform(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# count vector\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "count_vect = CountVectorizer(analyzer='word', token_pattern=r'\\w{1,}') \n",
    "count_vect.fit(df.clean_text) # regexp selects tokens of 1 or more alphanumeric characters\n",
    "\n",
    "xall_count = count_vect.transform(df.clean_text)\n",
    "xtrain_count = count_vect.transform(x_train)\n",
    "xtest_count = count_vect.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# tf-idf\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "# word-level tf-idf\n",
    "tfidf_vect = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', max_features=5000)\n",
    "tfidf_vect.fit(df.clean_text)\n",
    "xtrain_tfidf = tfidf_vect.transform(x_train)\n",
    "xtest_tfidf = tfidf_vect.transform(x_test)\n",
    "\n",
    "# ngram-level tf-idf \n",
    "tfidf_vect_ngram = TfidfVectorizer(analyzer='word', token_pattern=r'\\w{1,}', ngram_range=(2, 3), max_features=5000)\n",
    "tfidf_vect_ngram.fit(df.clean_text) # measures bi-grams and tri-grams\n",
    "xtrain_tfidf_ngram = tfidf_vect_ngram.transform(x_train)\n",
    "xtest_tfidf_ngram = tfidf_vect_ngram.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Latent Dirichlet Allocation model (with online variational Bayes algorithm)\n",
    "from sklearn import decomposition\n",
    "\n",
    "lda_model = decomposition.LatentDirichletAllocation(n_components=10, learning_method='online', max_iter=100)\n",
    "lda_fit = lda_model.fit_transform(xall_count)\n",
    "topics = lda_model.components_ \n",
    "vocab = count_vect.get_feature_names()\n",
    "\n",
    "# top keywords for each topic\n",
    "n_words = 10\n",
    "vocab = count_vect.get_feature_names()\n",
    "keywords = np.array(vocab)\n",
    "topic_keywords = []\n",
    "for topic_weights in topics:\n",
    "    top_keyword_locs = (-topic_weights).argsort()[:n_words]\n",
    "    topic_keywords.append(keywords.take(top_keyword_locs))\n",
    "df_topic_kw = pd.DataFrame(topic_keywords)\n",
    "df_topic_kw.columns = ['Word '+str(i) for i in range(df_topic_kw.shape[1])]\n",
    "df_topic_kw.index = ['Topic '+str(i) for i in range(df_topic_kw.shape[0])]\n",
    "df_topic_kw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dominant topic for each matrix\n",
    "topic_names = ['Topic ' + str(i) for i in range(lda_model.n_components)]\n",
    "df_doctop = pd.DataFrame(np.round(lda_fit, 2), columns=topic_names, index=df.index)\n",
    "dominant_topic = np.argmax(df_doctop.values, axis=1)\n",
    "df_doctop['dominant_topic'] = dominant_topic \n",
    "df_doctop['source'] = df.source\n",
    "df_doctop['label'] = df.label\n",
    "df_doctop.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the dominant topic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_doctop.groupby(['dominant_topic', 'source'])['source'].count().unstack().\\\n",
    "    plot(kind='bar', figsize=(15, 8), fontsize=14, ax=ax, cmap=plt.cm.get_cmap('Accent'))\n",
    "ax.set_title('Document Dominant Topics by Source', fontsize=18)\n",
    "ax.set_xlabel('Dominant Topic', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "ax.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# plot the dominant topic\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "df_doctop.groupby(['source', 'label'])['source'].count().unstack().\\\n",
    "    plot(kind='bar', figsize=(15, 8), fontsize=14, ax=ax, cmap=plt.cm.get_cmap('Accent'))\n",
    "ax.set_title('Document Dominant Topics by Source', fontsize=18)\n",
    "ax.set_xlabel('Dominant Topic', fontsize=14)\n",
    "ax.set_ylabel('Count', fontsize=14)\n",
    "plt.xticks(rotation=0)\n",
    "ax.legend(fontsize=14);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model wrapper function\n",
    "from sklearn import metrics\n",
    "\n",
    "def train_model(classifier, train_features, label, test_features):\n",
    "    # fit the training data on classifier\n",
    "    classifier.fit(train_features, label)\n",
    "    \n",
    "    # predict testing data labels\n",
    "    predictions = classifier.predict(test_features)\n",
    "    \n",
    "    return metrics.accuracy_score(predictions, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Naive Bayes\n",
    "from sklearn import naive_bayes\n",
    "\n",
    "# Count Vectors\n",
    "nb_cv = train_model(naive_bayes.MultinomialNB(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Naive Bayes] Count Vectors Accuracy:\", round(nb_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "nb_wl = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Naive Bayes] Word-Level TF-IDF Accuracy:\", round(nb_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "nb_nl = train_model(naive_bayes.MultinomialNB(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Naive Bayes] N-Gram-Level TF-IDF Accuracy:\", round(nb_nl, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Logistic Regression\n",
    "from sklearn import linear_model\n",
    "\n",
    "# Count Vectors\n",
    "lr_cv = train_model(linear_model.LogisticRegression(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Logistic Regression] Count Vectors Accuracy:\", round(lr_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "lr_wl = train_model(linear_model.LogisticRegression(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Logistic Regression] Word-Level TF-IDF Accuracy:\", round(lr_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "lr_nl = train_model(linear_model.LogisticRegression(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Logistic Regression] N-Gram TF-IDF Accuracy:\", round(lr_nl, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Support Vector Machines\n",
    "from sklearn import svm\n",
    "\n",
    "# Count Vectors\n",
    "svm_cv = train_model(svm.SVC(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Support Vector Machines] Count Vectors Accuracy:\", round(svm_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "svm_wl = train_model(svm.SVC(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Support Vector Machines] Word-Level TF-IDF Accuracy:\", round(svm_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "svm_nl = train_model(svm.SVC(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Support Vector Machines] N-Gram TF-IDF Accuracy:\", round(svm_nl, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest\n",
    "from sklearn import ensemble\n",
    "\n",
    "# Count Vectors\n",
    "rf_cv = train_model(ensemble.RandomForestClassifier(), xtrain_count, y_train, xtest_count)\n",
    "print(\"[Random Forest] Count Vectors Accuracy:\", round(rf_cv, 3))\n",
    "\n",
    "# Word-Level TF-IDF Vectors\n",
    "rf_wl = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf, y_train, xtest_tfidf)\n",
    "print(\"[Random Forest] Word-Level TF-IDF Accuracy:\", round(rf_wl, 3))\n",
    "\n",
    "# Ngram-Level TF-IDF Vectors\n",
    "rf_nl = train_model(ensemble.RandomForestClassifier(), xtrain_tfidf_ngram, y_train, xtest_tfidf_ngram)\n",
    "print(\"[Random Forest] N-Gram TF-IDF Accuracy:\", round(rf_nl, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# model performance table\n",
    "pd.DataFrame([[nb_cv, nb_wl, nb_nl],\n",
    "              [lr_cv, lr_wl, lr_nl],\n",
    "              [svm_cv, svm_wl, svm_nl],\n",
    "              [rf_cv, rf_wl, rf_nl]],             \n",
    "columns=['Count Vector', 'Word TF-IDF', 'n-Gram TF-IDF'], \n",
    "index=['Naive Bayes', 'Logistic Regression', 'Support Vector Machines', 'Random Forest']).round(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer.fit_on_texts(df.clean_text)\n",
    "word_index= tokenizer.word_index\n",
    "#print(word_index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[16, 28, 30], [32]]\n"
     ]
    }
   ],
   "source": [
    "test_data = [\n",
    "    'i really love this product',\n",
    "    'waste of money it does not work'\n",
    "]\n",
    "test_seq = tokenizer.texts_to_sequences(test_data)\n",
    "print(test_seq)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = tokenizer.texts_to_sequences(df.clean_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "padded = pad_sequences(sequences, padding = 'post', truncating= 'post', maxlen=42)\n",
    "#print(word_index)\n",
    "#print(sequences)\n",
    "#print(padded)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ 1  5 33  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0\n",
      "  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0  0]\n"
     ]
    }
   ],
   "source": [
    "print(padded[1,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 6 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "print(padded[2,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split dataset\n",
    "from sklearn import model_selection\n",
    "from sklearn import preprocessing\n",
    "\n",
    "# train-test split\n",
    "x_train, x_test, y_train, y_test = model_selection.train_test_split(df.clean_text, df.label) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Embedding(5120, 64, input_length=42),\n",
    "    tf.keras.layers.Flatten(),\n",
    "    tf.keras.layers.Dense(6, activation='relu'),\n",
    "    tf.keras.layers.Dense(1, activation='sigmoid')\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "model = keras.Sequential()\n",
    "model.add(keras.layers.Embedding(10000,16))\n",
    "model.add(keras.layers.GlobalAveragePooling1D())\n",
    "model.add(keras.layers.Dense(16, activation='relu'))\n",
    "model.add(keras.layers.Dense(1,activation='sigmoid'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "C3. # review video on how to explain hyperparameters in video tensorflow linear regression video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " embedding (Embedding)       (None, 42, 64)            327680    \n",
      "                                                                 \n",
      " flatten (Flatten)           (None, 2688)              0         \n",
      "                                                                 \n",
      " dense (Dense)               (None, 6)                 16134     \n",
      "                                                                 \n",
      " dense_1 (Dense)             (None, 1)                 7         \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 343,821\n",
      "Trainable params: 343,821\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'], run_eagerly=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val= x_train[:5120]\n",
    "x_train=x_train[5120:]\n",
    "y_val=y_train[:5120]\n",
    "y_train=y_train[5120:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/40\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-54-7b2a0bb54056>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mfitmodel\u001b[0m\u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m40\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m512\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_val\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_val\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\utils\\traceback_utils.py\u001b[0m in \u001b[0;36merror_handler\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m     65\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m  \u001b[1;31m# pylint: disable=broad-except\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     66\u001b[0m       \u001b[0mfiltered_tb\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_process_traceback_frames\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m__traceback__\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 67\u001b[1;33m       \u001b[1;32mraise\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mwith_traceback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfiltered_tb\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;32mfrom\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     68\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     69\u001b[0m       \u001b[1;32mdel\u001b[0m \u001b[0mfiltered_tb\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\anaconda3\\lib\\site-packages\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_batch_size, validation_freq, max_queue_size, workers, use_multiprocessing)\u001b[0m\n\u001b[0;32m   1393\u001b[0m         \u001b[0mlogs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtf_utils\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msync_to_numpy_or_python_type\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlogs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1394\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mlogs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1395\u001b[1;33m           raise ValueError('Unexpected result of `train_function` '\n\u001b[0m\u001b[0;32m   1396\u001b[0m                            \u001b[1;34m'(Empty logs). Please use '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1397\u001b[0m                            \u001b[1;34m'`Model.compile(..., run_eagerly=True)`, or '\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: Unexpected result of `train_function` (Empty logs). Please use `Model.compile(..., run_eagerly=True)`, or `tf.config.run_functions_eagerly(True)` for more information of where went wrong, or file a issue/bug to `tf.keras`."
     ]
    }
   ],
   "source": [
    "fitmodel= model.fit(x_train, y_train, epochs=40, batch_size=512, validation_data=(x_val, y_val), verbose=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
